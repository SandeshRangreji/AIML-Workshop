{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_pos = os.listdir('train/pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_li_pos = len(li_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_neg = os.listdir('train/neg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_li_neg = len(li_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence'] = ''\n",
    "df['sentiment'] = ''\n",
    "df['polarity'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len_li_pos + len_li_neg):\n",
    "    if i < len_li_pos :\n",
    "        sentence = open('train/pos/'+li_pos[i], encoding = 'utf-8').read()\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", li_pos[i]).group(1)\n",
    "        polarity = 1\n",
    "        df.loc[i] = [sentence, sentiment, polarity]\n",
    "    else:\n",
    "        sentence = open('train/neg/'+li_neg[i - len_li_pos], encoding = 'utf-8').read()\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", li_neg[i - len_li_pos]).group(1)\n",
    "        polarity = 0\n",
    "        df.loc[i] = [sentence, sentiment, polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment polarity\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...         9        1\n",
       "1  Homelessness (or Houselessness as George Carli...         8        1\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...        10        1\n",
       "3  This is easily the most underrated film inn th...         7        1\n",
       "4  This is not the typical Mel Brooks film. It wa...         8        1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>Towards the end of the movie, I felt it was to...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>This is the kind of movie that my enemies cont...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>I saw 'Descent' last night at the Stockholm Fi...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>Some films that you pick up for a pound turn o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>This is one of the dumbest films, I've ever se...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence sentiment polarity\n",
       "24995  Towards the end of the movie, I felt it was to...         4        0\n",
       "24996  This is the kind of movie that my enemies cont...         3        0\n",
       "24997  I saw 'Descent' last night at the Stockholm Fi...         3        0\n",
       "24998  Some films that you pick up for a pound turn o...         1        0\n",
       "24999  This is one of the dumbest films, I've ever se...         1        0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_sentences = []\n",
    "for i in range(len(df['sentence'])):\n",
    "    words = df['sentence'][i].lower().split(' ')\n",
    "    new_li = []\n",
    "    for w in words:\n",
    "        if w in contractions:\n",
    "            new_li.append(contractions[w])\n",
    "        else:\n",
    "            new_li.append(w)\n",
    "    \n",
    "    for ele in new_li:\n",
    "        if ele in stop_words:\n",
    "            new_li.remove(ele)\n",
    "            \n",
    "    string = \" \".join(new_li)\n",
    "    \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', string, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub('[m]{2,}', 'mm', text)\n",
    "    \n",
    "    modified_sentences.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bromwell high cartoon comedy  ran time some programs school life  as  teachers   35 years teaching profession lead believe bromwell high s satire much closer reality  teachers   scramble survive financially  insightful students can see right their pathetic teachers  pomp  pettiness the whole situation  remind the schools knew their students  saw the episode which student repeatedly tried burn the school  immediately recalled                      high  a classic line  inspector  i am to sack one your teachers  student  welcome to bromwell high  i expect many adults of my age think bromwell high is far fetched  a pity it isn t ',\n",
       " 'homelessness  or houselessness george carlin stated  been issue years never plan help street were considered human everything going school  work  vote matter  people think homeless just lost cause worrying things racism  war iraq  pressuring kids succeed  technology  elections  inflation  worrying they will next end streets <br  ><br  >but were given bet live streets month without luxuries once from home  entertainment sets  bathroom  pictures wall  computer  everything once treasure see it is like be homeless  goddard bolt s lesson <br  ><br  >mel brooks  who directs  stars as bolt plays rich man has everything world deciding make bet sissy rival  jeffery tambor  see live streets thirty days without the luxuries  if bolt succeeds  can wants future project making buildings  the bet s bolt is thrown the street bracelet on leg monitor his every move he cannot step the sidewalk  he is given the nickname pepto a vagrant it is written on his forehead bolt meets characters including a woman the name molly  lesley ann warren  ex dancer got divorce losing home  her pals sailor  howard morris  fumes  teddy wilson  are already used the streets  they are survivors  bolt isn t  he is used reaching mutual agreements like he once did when rich it is fight flight  kill be killed <br  ><br  >while the love connection molly bolt was not necessary plot  found  life stinks  be one mel brooks  observant films where prior being a comedy  shows a tender side compared his slapstick work as blazing saddles  young frankenstein  spaceballs the matter  show it is like something valuable losing the next day on the other hand making a stupid bet like rich people when do not know what to with money  maybe should give to the homeless instead using like monopoly money <br  ><br  >or maybe film inspire to help others ',\n",
       " 'brilliant over acting lesley ann warren  best dramatic hobo lady have ever seen  love scenes clothes warehouse second none  corn face classic  good anything blazing saddles  take lawyers also superb  being accused being turncoat  selling boss  being dishonest lawyer pepto bolt shrugs indifferently  i m lawyer  says  three funny words  jeffrey tambor  favorite later larry sanders show  fantastic too a mad millionaire wants crush ghetto  his character more malevolent usual  the hospital scene  the scene the homeless invade a demolition site  all time classics  look the legs scene the two big diggers fighting  one bleeds   movie gets better time see  which quite often  ',\n",
       " 'easily underrated film inn brooks cannon  sure  flawed  does give realistic view homelessness  unlike  say  citizen kane gave realistic view lounge singers  titanic gave realistic view italians idiots   many jokes fall flat  still  film very lovable a way many comedies not  to pull off a story some the most traditionally reviled members society truly impressive  the fisher king  its crap  either  only complaint is that brooks have cast someone else the lead  i love mel a director writer  not so much a lead  ',\n",
       " 'is typical mel brooks film  much less slapstick most movies actually plot followable  leslie ann warren made movie  is a fantastic  under rated actress  were moments could been fleshed a bit more  some scenes could probably been cut make room do so  all all  is worth price rent see it  the acting was good overall  brooks did a good job without his characteristic speaking directly the audience  again  warren was the best actor the movie   fume   sailor  played parts well ']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modified_sentences[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modified_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "final_df['sentence'] = ''\n",
    "final_df['sentiment'] = ''\n",
    "final_df['polarity'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len_li_pos + len_li_neg):\n",
    "    if i < len_li_pos :\n",
    "        sentence = modified_sentences[i]\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", li_pos[i]).group(1)\n",
    "        polarity = 1\n",
    "        final_df.loc[i] = [sentence, sentiment, polarity]\n",
    "    else:\n",
    "        sentence = modified_sentences[i]\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", li_neg[i - len_li_pos]).group(1)\n",
    "        polarity = 0\n",
    "        final_df.loc[i] = [sentence, sentiment, polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bromwell high cartoon comedy  ran time some pr...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>homelessness  or houselessness george carlin s...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brilliant over acting lesley ann warren  best ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>easily underrated film inn brooks cannon  sure...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>is typical mel brooks film  much less slapstic...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence sentiment polarity\n",
       "0  bromwell high cartoon comedy  ran time some pr...         9        1\n",
       "1  homelessness  or houselessness george carlin s...         8        1\n",
       "2  brilliant over acting lesley ann warren  best ...        10        1\n",
       "3  easily underrated film inn brooks cannon  sure...         7        1\n",
       "4  is typical mel brooks film  much less slapstic...         8        1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>24995</td>\n",
       "      <td>towards end movie  felt technical  felt like c...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24996</td>\n",
       "      <td>kind movie my enemies content watch time  it i...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24997</td>\n",
       "      <td>saw  descent  last night stockholm film festiv...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24998</td>\n",
       "      <td>films you pick pound turn rather good   23rd c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24999</td>\n",
       "      <td>one dumbest films  i have ever seen  rips near...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence sentiment polarity\n",
       "24995  towards end movie  felt technical  felt like c...         4        0\n",
       "24996  kind movie my enemies content watch time  it i...         3        0\n",
       "24997  saw  descent  last night stockholm film festiv...         3        0\n",
       "24998  films you pick pound turn rather good   23rd c...         1        0\n",
       "24999  one dumbest films  i have ever seen  rips near...         1        0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(r'C:/Users/Arshit/Text Classification/train_data.csv', header='sentence', index=None, sep=' ', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('train_data.csv', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bromwell high cartoon comedy  ran time some pr...</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>homelessness  or houselessness george carlin s...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brilliant over acting lesley ann warren  best ...</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>easily underrated film inn brooks cannon  sure...</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>is typical mel brooks film  much less slapstic...</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment  polarity\n",
       "0  bromwell high cartoon comedy  ran time some pr...          9         1\n",
       "1  homelessness  or houselessness george carlin s...          8         1\n",
       "2  brilliant over acting lesley ann warren  best ...         10         1\n",
       "3  easily underrated film inn brooks cannon  sure...          7         1\n",
       "4  is typical mel brooks film  much less slapstic...          8         1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        bromwell high cartoon comedy  ran time some pr...\n",
       "1        homelessness  or houselessness george carlin s...\n",
       "2        brilliant over acting lesley ann warren  best ...\n",
       "3        easily underrated film inn brooks cannon  sure...\n",
       "4        is typical mel brooks film  much less slapstic...\n",
       "                               ...                        \n",
       "24995    towards end movie  felt technical  felt like c...\n",
       "24996    kind movie my enemies content watch time  it i...\n",
       "24997    saw  descent  last night stockholm film festiv...\n",
       "24998    films you pick pound turn rather good   23rd c...\n",
       "24999    one dumbest films  i have ever seen  rips near...\n",
       "Name: sentence, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(final_df['sentence'])\n",
    "\n",
    "thresh=35\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "\n",
    "common = tot_cnt-cnt\n",
    "\n",
    "tokenizer = Tokenizer(num_words = common)\n",
    "tokenizer.fit_on_texts(final_df['sentence'])\n",
    "word2idx = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_word2idx = common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9253"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(final_df['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences, padding='post', maxlen=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = []\n",
    "for i in range(25000):\n",
    "    if i < 12500:\n",
    "        Y_train.append(1)\n",
    "    else:\n",
    "        Y_train.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.reshape(Y_train, (len(Y_train),)+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_li_pos = os.listdir('test/pos')\n",
    "len_test_li_pos = len(test_li_pos)\n",
    "\n",
    "test_li_neg = os.listdir('test/neg')\n",
    "len_test_li_neg = len(test_li_neg)\n",
    "\n",
    "test_df = pd.DataFrame()\n",
    "\n",
    "test_df['sentence'] = ''\n",
    "test_df['sentiment'] = ''\n",
    "test_df['polarity'] = ''\n",
    "\n",
    "for i in range(len_test_li_pos + len_test_li_neg):\n",
    "    if i < len_test_li_pos :\n",
    "        sentence = open('test/pos/'+test_li_pos[i], encoding = 'utf-8').read()\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", test_li_pos[i]).group(1)\n",
    "        polarity = 1\n",
    "        test_df.loc[i] = [sentence, sentiment, polarity]\n",
    "    else:\n",
    "        sentence = open('test/neg/'+test_li_neg[i - len_test_li_pos], encoding = 'utf-8').read()\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", test_li_neg[i - len_test_li_pos]).group(1)\n",
    "        polarity = 0\n",
    "        test_df.loc[i] = [sentence, sentiment, polarity]\n",
    "\n",
    "\n",
    "modified_sentences = []\n",
    "for i in range(len(test_df['sentence'])):\n",
    "    words = test_df['sentence'][i].lower().split(' ')\n",
    "    new_li = []\n",
    "    for w in words:\n",
    "        if w in contractions:\n",
    "            new_li.append(contractions[w])\n",
    "        else:\n",
    "            new_li.append(w)\n",
    "    \n",
    "    for ele in new_li:\n",
    "        if ele in stop_words:\n",
    "            new_li.remove(ele)\n",
    "            \n",
    "    string = \" \".join(new_li)\n",
    "    \n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', string, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    text = re.sub('[m]{2,}', 'mm', text)\n",
    "    \n",
    "    modified_sentences.append(text)\n",
    "    \n",
    "\n",
    "final_test_df = pd.DataFrame()\n",
    "\n",
    "final_test_df['sentence'] = ''\n",
    "final_test_df['sentiment'] = ''\n",
    "final_test_df['polarity'] = ''\n",
    "\n",
    "for i in range(len_test_li_pos + len_test_li_neg):\n",
    "    if i < len_test_li_pos :\n",
    "        sentence = modified_sentences[i]\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", test_li_pos[i]).group(1)\n",
    "        polarity = 1\n",
    "        final_test_df.loc[i] = [sentence, sentiment, polarity]\n",
    "    else:\n",
    "        sentence = modified_sentences[i]\n",
    "        sentiment = re.match(\"\\d+_(\\d+)\\.txt\", test_li_neg[i - len_test_li_pos]).group(1)\n",
    "        polarity = 0\n",
    "        final_test_df.loc[i] = [sentence, sentiment, polarity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_test = Tokenizer(num_words = common)\n",
    "tokenizer_test.fit_on_texts(final_test_df['sentence'])\n",
    "word2idx_test = tokenizer_test.word_index\n",
    "sequences_test = tokenizer_test.texts_to_sequences(final_test_df['sentence'])\n",
    "\n",
    "X_test = pad_sequences(sequences_test, padding='post', maxlen=200)\n",
    "\n",
    "Y_test = []\n",
    "for i in range(25000):\n",
    "    if i < 12500:\n",
    "        Y_test.append(1)\n",
    "    else:\n",
    "        Y_test.append(0)\n",
    "        \n",
    "Y_test = np.reshape(Y_test, (len(Y_test),)+(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 200)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arshit\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Arshit\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\Arshit\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Arshit\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Arshit\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "input_X = keras.Input(shape=(200,))\n",
    "\n",
    "X = layers.Embedding(len_word2idx, 128)(input_X)\n",
    "X = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(X)\n",
    "X = layers.Bidirectional(layers.LSTM(64))(X)\n",
    "\n",
    "out = layers.Dense(1, activation='sigmoid')(X)\n",
    "\n",
    "model = keras.Model(input_X, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 200, 128)          1184384   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 200, 128)          98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,382,145\n",
      "Trainable params: 1,382,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Arshit\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 512s 20ms/sample - loss: 0.3838 - acc: 0.8262\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 333s 13ms/sample - loss: 0.2173 - acc: 0.9195\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 340s 14ms/sample - loss: 0.1547 - acc: 0.9436\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 333s 13ms/sample - loss: 0.1117 - acc: 0.9612\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 334s 13ms/sample - loss: 0.0851 - acc: 0.9708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bb0d54db08>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=5, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 44s 2ms/sample - loss: 0.0454 - acc: 0.9898\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = model.evaluate(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss :  0.04535048822373152\n",
      "train_acc :  0.9898\n"
     ]
    }
   ],
   "source": [
    "print(\"train_loss : \", train_loss)\n",
    "print(\"train_acc : \", train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 47s 2ms/sample - loss: 1.5816 - acc: 0.5396\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss :  1.5815725871276856\n",
      "test_acc :  0.53964\n"
     ]
    }
   ],
   "source": [
    "print(\"test_loss : \", test_loss)\n",
    "print(\"test_acc : \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
